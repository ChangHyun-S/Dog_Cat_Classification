{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "dl_lab_cnn_dogcat_심창현.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfvRP8c9oFcn",
        "colab_type": "text"
      },
      "source": [
        "# Dog, cat image classification problem set\n",
        "\n",
        "* 이번 학습에서는 처음부터 끝까지 Dog, cat dataset에 대한 분류 model을 구현합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bMlMz4EoFco",
        "colab_type": "text"
      },
      "source": [
        "### [CUDA](http://pytorch.org/docs/stable/cuda.html)\n",
        "\n",
        "* cuda를 이용하겠습니다\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghm6aX2UoFcp",
        "colab_type": "code",
        "outputId": "efc3aa99-8607-4077-acbd-d8d5a7c62614",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "#train_on_gpu = False\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbfbVWvIoFcs",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Load the [Data](http://pytorch.org/docs/stable/torchvision/datasets.html)\n",
        "\n",
        "* 아미지를 다운로드 받습니다\n",
        "* 폴더별로\n",
        " - test\n",
        " - train\n",
        " - validation\n",
        "\n",
        " data를 받습니다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-vIYeDvw0X5",
        "colab_type": "code",
        "outputId": "7cbd5683-1d0c-4013-e5ea-603f51073ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip install googledrivedownloader"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7_ItD54w8ii",
        "colab_type": "code",
        "outputId": "18c28129-7756-4643-b215-24f47eb0c89a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from os.path import exists\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "import tarfile \n",
        "\n",
        "#if exists(\"./Cat_Dog_data.tgz\"):\n",
        "#    !rm -rf ./Cat_Dog_data.tgz\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='1WpY0qpe7yF5C5M52z1BMIzYVpDYiU3OV',\n",
        "                                    dest_path = './Cat_Dog_data.tgz')\n",
        "\n",
        "tf = tarfile.open(\"Cat_Dog_data.tgz\")\n",
        "tf.extractall()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1WpY0qpe7yF5C5M52z1BMIzYVpDYiU3OV into ./Cat_Dog_data.tgz... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNnl0wVnxvLM",
        "colab_type": "text"
      },
      "source": [
        "## Problem 1 [20 points]: \n",
        "\n",
        "* Training, validation, test를 위한 dataloader, transform을 적절하게 준비해주세요\n",
        "* 아래 data 준비하는 코딩을 수행하고, 아래 markdown에 준비한 과정 및 이유를 구체적으로 설명하세요\n",
        "* 아래 답안 작성에 data의 구조에 대해서 설명하세요\n",
        "* 코드에는 주석을 달아주세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiZz3-P3ysrV",
        "colab_type": "code",
        "outputId": "909c420d-ce7f-4744-9d46-de878e08530f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Coding\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# batch size\n",
        "batch_size = 10\n",
        "\n",
        "# 이미지 전처리\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30), # 랜덤 각도 회전\n",
        "                                       transforms.RandomResizedCrop(224), # 랜덤 리사이즈 크롭\n",
        "                                       transforms.RandomHorizontalFlip(), # 랜덤으로 수평 뒤집기\n",
        "                                       transforms.ToTensor(), # 이미지를 텐서로\n",
        "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]) # RGB 모든 픽셀을 0.5로 나눈 뒤 0.5로 뺌\n",
        "                                                                                                \n",
        "test_transforms = transforms.Compose([transforms.Resize(255), # 이미지 리사이즈\n",
        "                                      transforms.CenterCrop(224), # 중앙 224 x 244 크롭\n",
        "                                      transforms.ToTensor(), \n",
        "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]) # 이미지를 텐서로\n",
        "\n",
        "# training, validation, testset 로드\n",
        "trainset = ImageFolder(root='./train', transform=train_transforms)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "                                                              \n",
        "validset = ImageFolder(root='./validation', transform=train_transforms)\n",
        "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 테스트 셋은 셔플 안함\n",
        "testset = ImageFolder(root='./test', transform=test_transforms)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size)\n",
        "\n",
        "# cat dog 클래스 분류\n",
        "classes = ['cat', 'dog']\n",
        "\n",
        "print(len(trainset))\n",
        "print(len(testset))\n",
        "print(len(validset))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20000\n",
            "2500\n",
            "2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4Ad2T8wyDJN",
        "colab_type": "text"
      },
      "source": [
        "**분석 및 설명:**\n",
        "\n",
        "배치 사이즈는 10으로 한 뒤, 성능 향상을 위해 training transforms에서 랜덤 각도회전, 랜덤 리사이즈 크롭, 랜덤 뒤집기를 한다. \n",
        "그리고 test transfrom은 테스트셋이기 때문에 리사이즈와 크롭, 텐서만 적용시킨다\n",
        "\n",
        "그 후에 training set, validation set, test set을 로드시킨 후 cat dog 클래스로 분류한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA22N127BhrH",
        "colab_type": "code",
        "outputId": "411db540-f358-4a6d-a392-5f3233d332bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''\n",
        "############## 데이터 로드 테스트용\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def imshow(img):\n",
        "    img = img * 0.5 + 0.5 \n",
        "    plt.imshow(np.transpose(img, (1, 2, 0)))  \n",
        "\n",
        "dataiter = iter(trainloader) \n",
        "images, labels = dataiter.next()\n",
        "images = images.numpy() \n",
        "\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "\n",
        "for idx in np.arange(20): \n",
        "    ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])\n",
        "    imshow(images[idx])\n",
        "    ax.set_title(classes[labels[idx]])\n",
        "\n",
        "print(images.shape)\n",
        "'''"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n############## 데이터 로드 테스트용\\nimport matplotlib.pyplot as plt\\n%matplotlib inline\\n\\ndef imshow(img):\\n    img = img * 0.5 + 0.5 \\n    plt.imshow(np.transpose(img, (1, 2, 0)))  \\n\\ndataiter = iter(trainloader) \\nimages, labels = dataiter.next()\\nimages = images.numpy() \\n\\nfig = plt.figure(figsize=(25, 4))\\n\\nfor idx in np.arange(20): \\n    ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])\\n    imshow(images[idx])\\n    ax.set_title(classes[labels[idx]])\\n\\nprint(images.shape)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4bXK3BxoFdE",
        "colab_type": "text"
      },
      "source": [
        "## Problem 2 [20 point]: Define the Network Architecture\n",
        "\n",
        "* 구현하고자하는 network을 작성해주세요\n",
        "* 아래 구현 방법과 이유를 구체적으로 설명하세요\n",
        "* 코드에는 주석을 달아주세요. \n",
        "* 아래 모델을 구체적으로 설명하고, 설정 이유를 작성해주세요\n",
        "* 본 과정에서는 직접 network을 구현하고, transfer learning은 활용하지 않도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaNxUAd4oFdF",
        "colab_type": "code",
        "outputId": "17aae4ef-ef93-4bf5-e6f7-5e4287e90234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# 코드 작성\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# CNN 작성\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "\n",
        "      # input image = 224 x 244 x 3\n",
        "\n",
        "      # 224 x 224 x 3 --> 112 x 112 x 32 maxpool\n",
        "      self.conv1 = nn.Conv2d(3, 32, 3, padding=1) \n",
        "      # 112 x 112x 32 --> 56 x 56 x 64 maxpool\n",
        "      self.conv2 = nn.Conv2d(32, 64, 3, padding=1) \n",
        "      # 56 x 56 x 64 --> 28 x 28 x 128 maxpool\n",
        "      self.conv3 = nn.Conv2d(64, 128, 3, padding=1)     \n",
        "      # 28 x 28 x 128 --> 14 x 14 x 256 maxpool\n",
        "      self.conv4 = nn.Conv2d(128, 256, 3, padding=1)    \n",
        "\n",
        "      # maxpool 2 x 2\n",
        "      self.pool = nn.MaxPool2d(2, 2)\n",
        "      \n",
        "      # 28 x 28 x 128 vector flat 512개\n",
        "      self.fc1 = nn.Linear(256 * 14 * 14, 512)\n",
        "      # 카테고리 2개 클래스\n",
        "      self.fc2 = nn.Linear(512, 2) \n",
        "      \n",
        "      # dropout 적용\n",
        "      self.dropout = nn.Dropout(0.5) # 0.25 해보고 0.5로 해보기. 값 저장하고나서\n",
        "\n",
        "    def forward(self, x):\n",
        "      # conv1 레이어에 relu 후 maxpool. 112 x 112 x 32\n",
        "      x = self.pool(F.relu(self.conv1(x)))\n",
        "      # conv2 레이어에 relu 후 maxpool. 56 x 56 x 64\n",
        "      x = self.pool(F.relu(self.conv2(x)))\n",
        "      # conv3 레이어에 relu 후 maxpool. 28 x 28 x 128\n",
        "      x = self.pool(F.relu(self.conv3(x)))\n",
        "      # conv4 레이어에 relu 후 maxpool. 14 x 14 x 256\n",
        "      x = self.pool(F.relu(self.conv4(x)))\n",
        "\n",
        "      # 이미지 펴기\n",
        "      x = x.view(-1, 256 * 14 * 14) \n",
        "      # dropout 적용\n",
        "      x = self.dropout(x)\n",
        "      # fc 레이어에 삽입 후 relu\n",
        "      x = F.relu(self.fc1(x))\n",
        "      # dropout 적용\n",
        "      x = self.dropout(x)\n",
        "      \n",
        "      # 마지막 logsoftmax 적용\n",
        "      x = F.log_softmax(self.fc2(x), dim=1)\n",
        "      return x\n",
        "\n",
        "model = Net() # 모델 생성\n",
        "print(model) # 출력\n",
        "\n",
        "if train_on_gpu:\n",
        "    model.cuda() # cuda 사용\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkP09gUJzKVc",
        "colab_type": "text"
      },
      "source": [
        "**분석 및 설명:**\n",
        "\n",
        "정규화를 한 이미지 사이즈인 224 x 224 x 3 을 삽입한다. maxpool을 한 뒤 컨볼루션 3 x 3 x 3을 적용시키고, conv1에서 32개의 아웃풋을 적용하였기 때문에 112 x 112 x 32으로 첫번째 계산이 된다.\n",
        "그 후에 conv2에서 동일하게 64개의 아웃풋을 적용한 후 maxpool 적용시켰기 때문에 56 x 56 x 64으로 계산이 되고, conv3에서 128개의 아웃풋, maxpool 적용시키면  28 x 28 x 128으로 계산이 되고, 마지막으로 conv4에서 14 x 14 x 256의 아웃풋이 나온다.\n",
        "\n",
        "그리고 이미지를 편 후 오버피팅 방지를 위해 드롭아웃을 시킨다. 그리고 히든 레이어에 삽입 후 relu를 적용시킨 뒤 동일하게 드롭아웃 후 log_softmax를 적용시킨다. 만약 loss함수에서 CrossEntropyLoss를 사용 할 경우에는 log_softmax를 사용하지 않는다.\n",
        "\n",
        "마지막으로 모델을 생성한 후 gpu를 사용한다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xukdFNh3oFdH",
        "colab_type": "text"
      },
      "source": [
        "## Problem 3 [5 point]: Specify Loss Function\n",
        "\n",
        "* Loss 함수와 optimizer를 구현하세요\n",
        "* 선정 이유를 설명하세요\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuczyoY5oFdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 코드\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64psu2RjzdrZ",
        "colab_type": "text"
      },
      "source": [
        " **설명:** loss 함수에서 NLLLoss와 CrossEntropyLoss 중 CrossEntropyLoss는 네트워크에서 log_softmax를 사용하지 않을때 사용하는 함수라고 하여 NLLLoss를 선택하였다.\n",
        " \n",
        "optimizer는 SGD, Adam을 사용해보았는데 성능 검증 단계에서 Adam은 로스율이 0.69으로 고정되어 성능이 70%정도가 나왔다.\n",
        "SGD는 정상적으로 로스율이 감소되어 성능이 80%이상이 나와 SGD를 사용하였다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcIVfJz9oFdJ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Problem 4 [30 point]: Train the Network\n",
        "\n",
        "* training loss와 validation loss를 기록하며 training을 구현하세요\n",
        "* 만약 validation loss가 최소화된 모델을 저장하세요\n",
        "* 코드에는 모두 주석을 포함해주세요\n",
        "* training과정을 설명하고, training 결과를 분석해주세요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "fjBJWFIboFdJ",
        "colab_type": "code",
        "outputId": "46e6e7de-102a-4ab6-f9c0-e6acdce33832",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        }
      },
      "source": [
        "# 코드 작성\n",
        "\n",
        "# epochs 30\n",
        "n_epochs = 30\n",
        "\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    # train, valid loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    # 모델 트레이닝\n",
        "    model.train()\n",
        "    # training set\n",
        "    for data, target in trainloader:\n",
        "        # cuda 사용\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        # 역전파 실행 전 gradient 0 초기화\n",
        "        optimizer.zero_grad()\n",
        "        # 모델 계산 후 output 저장\n",
        "        output = model(data)\n",
        "        # 로스율 계산\n",
        "        loss = criterion(output, target)\n",
        "        # 가중치 계산\n",
        "        loss.backward()\n",
        "        # 모델 parameter 업데이트\n",
        "        optimizer.step()\n",
        "        # 트레이닝 로스 계산\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    # validation 모델\n",
        "    model.eval()\n",
        "    validation_iter = iter(validloader)\n",
        "    for data, target in validation_iter:\n",
        "        # cuda 사용\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # 모델 계산 후 output 저장\n",
        "        output = model(data)\n",
        "        # 로스율 계산\n",
        "        loss = criterion(output, target)\n",
        "        # validation 로스율 계산\n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # 평균 로스율\n",
        "    train_loss = train_loss/len(trainloader.sampler)\n",
        "    valid_loss = valid_loss/len(validloader.sampler)\n",
        "        \n",
        "    # training set, validation set 로스율 출력\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss))\n",
        "    \n",
        "    # 로스율이 낮아지면 model_catdog.pt에 저장\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'model_catdog.pt')\n",
        "        valid_loss_min = valid_loss"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.672942 \tValidation Loss: 0.651699\n",
            "Validation loss decreased (inf --> 0.651699).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.635230 \tValidation Loss: 0.600129\n",
            "Validation loss decreased (0.651699 --> 0.600129).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.602986 \tValidation Loss: 0.571484\n",
            "Validation loss decreased (0.600129 --> 0.571484).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 0.578175 \tValidation Loss: 0.553068\n",
            "Validation loss decreased (0.571484 --> 0.553068).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 0.566229 \tValidation Loss: 0.539351\n",
            "Validation loss decreased (0.553068 --> 0.539351).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 0.549421 \tValidation Loss: 0.542284\n",
            "Epoch: 7 \tTraining Loss: 0.537756 \tValidation Loss: 0.524534\n",
            "Validation loss decreased (0.539351 --> 0.524534).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 0.525244 \tValidation Loss: 0.514252\n",
            "Validation loss decreased (0.524534 --> 0.514252).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 0.518789 \tValidation Loss: 0.510042\n",
            "Validation loss decreased (0.514252 --> 0.510042).  Saving model ...\n",
            "Epoch: 10 \tTraining Loss: 0.507306 \tValidation Loss: 0.486674\n",
            "Validation loss decreased (0.510042 --> 0.486674).  Saving model ...\n",
            "Epoch: 11 \tTraining Loss: 0.501918 \tValidation Loss: 0.504940\n",
            "Epoch: 12 \tTraining Loss: 0.485993 \tValidation Loss: 0.460263\n",
            "Validation loss decreased (0.486674 --> 0.460263).  Saving model ...\n",
            "Epoch: 13 \tTraining Loss: 0.476753 \tValidation Loss: 0.504909\n",
            "Epoch: 14 \tTraining Loss: 0.467818 \tValidation Loss: 0.473384\n",
            "Epoch: 15 \tTraining Loss: 0.462003 \tValidation Loss: 0.447323\n",
            "Validation loss decreased (0.460263 --> 0.447323).  Saving model ...\n",
            "Epoch: 16 \tTraining Loss: 0.453824 \tValidation Loss: 0.438522\n",
            "Validation loss decreased (0.447323 --> 0.438522).  Saving model ...\n",
            "Epoch: 17 \tTraining Loss: 0.442220 \tValidation Loss: 0.422373\n",
            "Validation loss decreased (0.438522 --> 0.422373).  Saving model ...\n",
            "Epoch: 18 \tTraining Loss: 0.431566 \tValidation Loss: 0.445908\n",
            "Epoch: 19 \tTraining Loss: 0.421735 \tValidation Loss: 0.404463\n",
            "Validation loss decreased (0.422373 --> 0.404463).  Saving model ...\n",
            "Epoch: 20 \tTraining Loss: 0.416640 \tValidation Loss: 0.398900\n",
            "Validation loss decreased (0.404463 --> 0.398900).  Saving model ...\n",
            "Epoch: 21 \tTraining Loss: 0.404807 \tValidation Loss: 0.385343\n",
            "Validation loss decreased (0.398900 --> 0.385343).  Saving model ...\n",
            "Epoch: 22 \tTraining Loss: 0.395791 \tValidation Loss: 0.414803\n",
            "Epoch: 23 \tTraining Loss: 0.388006 \tValidation Loss: 0.367150\n",
            "Validation loss decreased (0.385343 --> 0.367150).  Saving model ...\n",
            "Epoch: 24 \tTraining Loss: 0.373407 \tValidation Loss: 0.380415\n",
            "Epoch: 25 \tTraining Loss: 0.369945 \tValidation Loss: 0.343832\n",
            "Validation loss decreased (0.367150 --> 0.343832).  Saving model ...\n",
            "Epoch: 26 \tTraining Loss: 0.359617 \tValidation Loss: 0.350263\n",
            "Epoch: 27 \tTraining Loss: 0.357875 \tValidation Loss: 0.331439\n",
            "Validation loss decreased (0.343832 --> 0.331439).  Saving model ...\n",
            "Epoch: 28 \tTraining Loss: 0.342905 \tValidation Loss: 0.305481\n",
            "Validation loss decreased (0.331439 --> 0.305481).  Saving model ...\n",
            "Epoch: 29 \tTraining Loss: 0.340852 \tValidation Loss: 0.313114\n",
            "Epoch: 30 \tTraining Loss: 0.327056 \tValidation Loss: 0.329197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkF7i-6Y0EAF",
        "colab_type": "text"
      },
      "source": [
        "**분석 및 설명:** \n",
        "\n",
        "epochs는 30으로 설정한다.\n",
        "\n",
        "트레이닝 모델을 불러온 뒤 gradient를 0으로 초기화시킨다. 그 후에 모델링을 하고 로스율을 계산하고 가중치를 계산한다.\n",
        "그리고 모델의 parameter를 업데이트 한 후 마지막 트레이닝 로스를 계산한다.\n",
        "\n",
        "완료가 되면 validation 모델을 불러온 뒤 로스를 계산한다.\n",
        "\n",
        "validation까지 완료가 되면 training set과 validation set의 평균 로스율을 계산하여 출력한다.\n",
        "\n",
        "만약 validation 로스율이 기존보다 낮아진다면 model_catdog.pt에 저장시킨다.\n",
        "\n",
        "출력 결과를 분석하면 정상적으로 Training Loss와 Validation Loss가 줄어드는 모습을 볼 수 있으며 가끔씩 Loss가 올라 저장이 안되는 경우도 발생하지만 정상적으로 Loss가 감소되었다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqX__Ju3oFdL",
        "colab_type": "text"
      },
      "source": [
        "## Problem 5 [5 point] Validation Loss가 최소화된 Model가져오기\n",
        "\n",
        "* 최소 validation loss를 갖는 model을 불러옵니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LF9TzTWoFdM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "68335161-7337-490a-892c-fec9f91b181b"
      },
      "source": [
        "# 코드 작성\n",
        "\n",
        "# 최소 로스율 모델 로딩\n",
        "model.load_state_dict(torch.load('model_catdog.pt'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLg9vQC2oFdR",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Problem 6 [20point]: Test the Trained Network\n",
        "\n",
        "* Test set을 활용하여 성능 검증\n",
        "* Accuracy (분류 성공률)와 test loss를 출력하세요\n",
        "* 코드에는 주석을 달아주세요\n",
        "* 아래 test 결과에 대해서 간단하게 설명/분석 해주세요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh_Pu57ToFdR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "6624b3dd-1086-446a-91b0-27ed5b69028d"
      },
      "source": [
        "# 코드 작성\n",
        "\n",
        "# cat dog이기 때문에 2개 클래스\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(2))\n",
        "class_total = list(0. for i in range(2))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for data, target in testloader:\n",
        "    # cuda 사용\n",
        "    if train_on_gpu:\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "    # 데이터를 output에 삽입\n",
        "    output = model(data)\n",
        "    # loss율 계산\n",
        "    loss = criterion(output, target)\n",
        "    # loss율 업데이트\n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    # 1차원, 정답률 확인\n",
        "    _, pred = torch.max(output, 1)    \n",
        "    # pred와 데이터를 비교한다\n",
        "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "    # torrect_tensor를 numpy로 바꾼 뒤 gpu 계산 또는 cpu 계산\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    # 몇 개 맞췄나 계산\n",
        "    for i in range(batch_size): # 배치 사이즈로\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "        # batch_size 32 넣으면 index 오류가 발생함. 만약 배치사이즈 32넣을때 강제로 1250장씩 분류하면 중지되도록 설정\n",
        "        # 평소에는 주석\n",
        "        #if class_total == [1250.0, 1250.0]:\n",
        "          #break\n",
        "\n",
        "# 로스율 평균 계산\n",
        "test_loss = test_loss/len(testloader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(2):\n",
        "    # 각 클래스 별 확률 출력\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "# 최종 확률 출력\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.216353\n",
            "\n",
            "Test Accuracy of   cat: 91% (1148/1250)\n",
            "Test Accuracy of   dog: 89% (1123/1250)\n",
            "\n",
            "Test Accuracy (Overall): 90% (2271/2500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywjwrJ691eL_",
        "colab_type": "text"
      },
      "source": [
        "**분석 및 설명:**\n",
        " \n",
        "클래스가 cat, dog 2개의 클래스이기 때문에 class_correct와 class_total의 크기를 2으로 지정한다.\n",
        "\n",
        "gpu를 사용하여 테스트 셋을 검증한다. Loss율을 계산하고 torch.max를 통해 정답률을 확인한다. 그리고 pred와 데이터를 비교하여 for문에서 배치 사이즈만큼 정답률을 계산한다.\n",
        "\n",
        "그런데 배치사이즈를 32으로 설정했을 때 인덱스 범위 오류가 발생한다. 그래서 배치사이즈 32으로 테스트 할 때 강제로 class_total이 각각 1250장을 분류하면 break 되도록 설정해두었다. 주석처리\n",
        "\n",
        "마지막으로 테스트셋의 로스율을 계산한 후 출력하며, 각 cat, dog 클래스에 대한 정답 확률을 출력하고 마지막으로 최종 확률을 출력한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkhG9np03CEm",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Problem 7: 전체적인 총평\n",
        "\n",
        "* Data준비, Training과 validation 과정에서 성능 개선을 위해서 수행한 과정과 성공/실패 이유를 분석해주세요\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCr5fHLi3UIQ",
        "colab_type": "text"
      },
      "source": [
        "**설명:**\n",
        "\n",
        "1. batch_size 32 / Normalize 0.5 / 컨볼루션 3개 / Dropout 0.5 / Optimizer SGD 0.03 적용했을 때 \n",
        "\n",
        "Test Loss: 0.542767\n",
        "\n",
        "Test Accuracy of   cat: 86% (1080/1250)\n",
        "\n",
        "Test Accuracy of   dog: 58% (733/1250)\n",
        "\n",
        "Test Accuracy (Overall): 72% (1813/2500)\n",
        "\n",
        ".\n",
        "\n",
        "2. batch_size 32 / Normalize mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) / 컨볼루션 3개 / Dropout 0.25 / Optimizer SGD 0.01 적용했을 때 \n",
        "\n",
        "Test Loss: 0.382337\n",
        "\n",
        "Test Accuracy of   cat: 77% (964/1250)\n",
        "\n",
        "Test Accuracy of   dog: 88% (1112/1250)\n",
        "\n",
        "Test Accuracy (Overall): 83% (2076/2500)\n",
        "\n",
        ".\n",
        "\n",
        "3. batch_size 32 / Normalize mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) / 컨볼루션 3개 / Dropout 0.5 / Optimizer SGD 0.01 적용했을 때 \n",
        "\n",
        "Test Loss: 0.392692\n",
        "\n",
        "Test Accuracy of   cat: 77% (970/1250)\n",
        "\n",
        "Test Accuracy of   dog: 87% (1093/1250)\n",
        "\n",
        "Test Accuracy (Overall): 82% (2063/2500)\n",
        "\n",
        ".\n",
        "\n",
        "4. batch_size 10 / Normalize mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) / 컨볼루션 4개 / Dropout 0.5 / Optimizer SGD 0.01 적용했을 때 \n",
        "\n",
        "Test Loss: 0.216353\n",
        "\n",
        "Test Accuracy of   cat: 91% (1148/1250)\n",
        "\n",
        "Test Accuracy of   dog: 89% (1123/1250)\n",
        "\n",
        "Test Accuracy (Overall): 90% (2271/2500)\n",
        "\n",
        ".\n",
        "\n",
        "데이터 셋 준비 단계에서 평균과 표준편차를 직접 계산하려 했지만 계산하는 방법을 찾기 어려워 가장 많이 쓰는 std와 mean을(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) 추가하였다. 그리고 배치사이즈를 10, 20, 32, 64를 적용시켜봤는데 10이 성능이 90%으로 가장 좋았다.\n",
        "\n",
        "트레이닝 부분에서는 처음에 드롭아웃을 0.25으로 적용시켜 트레이닝 하였다. 그 후에 드롭아웃을 0.5으로 변경시켜 트레이닝 해보니 0.5으로 설정한 결과보다 0.25의 결과값이 1% 더 높았다.\n",
        "\n",
        "optimizer를 SGD와 Adam을 사용해보았는데, SGD는 트레이닝 하는 과정에서 로스율이 0.3 후반까지 정상적으로 떨어지는 반면에 Adam 로스율이 0.69으로 거의 고정되어 더 이상 낮아지지 않았다. \n",
        "\n",
        "그래서 batch size가 32로 설정한 후 Adam의 결과는 78%의 결과가 나왔고, SGD를 적용했을 때에는 정상적으로 로스율이 낮아지면서 분류 확률이 83%가 나왔다. 구글에 검색을 해 보았을때는 SGD와 Adam중 하나를 고르라고 하면 성능이 좋은 Adam으로 고르라고 나와있지만 직접 트레이닝을 해 보니 정 반대의 결과가 나타났다. (참고 사이트 : http://www.gisdeveloper.co.kr/?p=8443)\n",
        "\n",
        "많은 테스트 중 성능이 좋게 나온 모델 4가지를 선정하였다. cnn을 구현해보니 배치 사이즈와 정규화 그리고 optimizer를 수정하면 성능이 가장 큰 폭으로 변화하였다. 이미지를 정규화할 때 직접 이미지를 계산하면 더 성능이 좋아질 수 있었겠지만 방법을 찾지 못해 가장 보편적으로 많이 쓴 값을 넣은것이 아쉬운점이다.\n",
        "\n",
        "따라서 여러 테스트 중 가장 성능이 높게 나온 모델은 성공률이 90%인 batch_size 10 / Normalize mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) / 컨볼루션 4개 / Dropout 0.5 / Optimizer 0.01 적용했을 때 이다."
      ]
    }
  ]
}